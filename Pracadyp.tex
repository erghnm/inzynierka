\documentclass[skorowidz,palatino,xodstep]{dyplomWEZUT}
%&platex --translate-file=cp1250pl
%\documentclass[skorowidz,brudnopis,palatino]{dyplomPS}

 \nrwersji {0.2}

\author   {Jêdrzej £ukasiuk}%
\nralbumu {21746}
\email    {nick@zut.edu.pl}
%
%\author   {Robert Nowicki}
%\nralbumu {55212}

\title    {Programowa implementacja filtrów Gabora w~procesie automatycznej klasyfikacji obiektów}
\kierunek {Geodezja i Kartografia}%
%\specjalnosc{Uk³ady i~Systemy Elektroniczne}

\date     {2016}%
\miejsce  {Szczecin}%

\opiekun  {prof.~dr~hab.~in¿.~Józef~Sanecki}%
\jednostka{Instytut In¿ynierii Ruchu Morskiego}%

\newcommand{\zmien}[1]{!!!!!!!!!\textbf{#1}!!!!!!!!!!!}

\makeglossary
% Polecenie konieczne do wygenerowania plików z wykazem skrótów i oznaczeñ
% makeindex -s Pracadyp.ist -t Pracadyp.glg -o Pracadyp.gls Pracadyp.glo


\newcommand{\ber}{\begin{eqnarray*}}
\newcommand{\eer}{\end{eqnarray*}}
\newcommand{\beq}{\begin{eqnarray}}
\newcommand{\eeq}{\end{eqnarray}}
\newcommand{\bd}{\begin{displaymath}}
\newcommand{\ed}{\end{displaymath}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}


\begin{document}

\begin{streszczenie}
\textcolor{red}{Streszczenie by³o pisane przed podzia³em rozdzia³u 3 na 2 czêœci, w zwi¹zku z czym zmieni siê}

Praca sk³ada siê z 3 rozdzia³ów, wprowadzenia i zakoñczenia. Skupiono siê w niej na analizie mo¿liwoœci wykorzystania filtrów Gabora w procesie zdalnego rozpoznania obiektów na zobrazowaniach fotogrametrycznych. Dwa pierwsze rozdzia³y maj¹ charakter teoretyczny. W pierwszym z nich opisana zosta³a struktura cyfrowych obrazów rastrowych, a tak¿e wprowadzone zosta³o pojêcie filtracji splotowej. Dodatkowo szczegó³owo scharakteryzowany zosta³ filtr Gabora, zarówno w dziedzinie czasowej, jak i czêstotliwoœciowej. Drugi rozdzia³a³ traktuje o klasyfikacji w teledetekcji. Zaprezentowane s¹ w nim typowe metody oraz podejœcia do tego procesu, wraz z~przyk³adami. Trzeci rodzia³ przedstawia wyniki przeprowadzonych przez autora badañ. Wskazano w nim metodykê prowadzonych dzia³añ, oraz ziulustrowano praktyczn¹ weryfikacjê algorytmu dla 3 ró¿nych przypadków. Podsumowanie i wnioski z przeprowadzonych prac stanowi¹ treœæ zakoñczenia pracy.
\end{streszczenie}

\slowakluczowe{filtry Gabora, klasyfikacja, zdalne rozpoznanie terenu}


\tytulang{Software implementation of Gabor filters in the process of automatic object classification}

\begin{abstract}
This thesis consists three chapters, introduction and conclusion. It focused on the analysis of the possibilities of using Gabor filters in the process of remote identification of objects on imaging photogrammetry and remote sensing (?). The first two chapters are theoretical. The first one describes the structure of the digital raster images and also introduced the concept of convolution filtering. Additionally the Gabor filter was characterized in detail, both the time and the frequency domains. The second chapter deals with the classification in remote sensing. It presented the conventional methods and approaches to this process, including examples. The third section presents the results of research conducted by the author. It indicated  the methodology of operations, and illustrate practical verification of the algorithm for three different cases. Summary and conclusions of the work are the contents of the completion of the work.
%\newline \\ \textcolor{red}{POPROSIÆ ADAMA O SPRAWDZENIE POPRAWNOŒCI GRAMATYCZNEJ}
\end{abstract}

\keywords{Gabor filters, classification, remote reconnaissance}

%% TO JEST TA ŒMIESZNA 'WK£ADKA' - EWENTUALNIE MO¯NA ZMERGOWAÆ OSOBNYM PROGRAMEM DWA GOTOWE PLIKI
\includepdf[pages=-]{tabela.pdf}

\maketitle 

\printglossary

\Wprowadzenie 

Podstaw¹ procesu zdalnego badania œrodowiska (ZBŒ) jest analiza i interpretacja zdjêæ pozyskanych zdalnie. Przez pojêcie interpretacji mo¿emy tu rozumieæ przede wszystkim wykrywanie i rozpoznawanie obiektów, jak równie¿ okreœlenie ich cech iloœciowych i~jakoœciowych.  \cite{Tele}

Klasyczne podejœcie do interpretacji zdjêæ oparte jest o analizê wielospektraln¹. Analiza ta zak³ada, ¿e piksele obrazu reprezentuj¹ce ten sam obiekt maj¹ podobne wartoœci odpowiedzi spektralnej. Wobec tego w przestrzeni spektralnej bêd¹ skupia³y siê w grupach. % TUTAJ BYM COŒ DODA£ GENERALNIE
%% TUTAJ JESZCZE RAZ PRZEMYŒLEÆ ... (???)

Niew¹tpliwie podejœcie te ma swoje oczywiste zalety (prostota realizacji), jednak nie zawsze jest rozwi¹zaniem optymalnym. %Spoœród innych algorytmów s³u¿acych  do klasyfikacji zdjêæ szczególnie obiecuj¹cym wydajê siê byæ tzw. algorytm klasyfikacji obiektowej. 
Innym mo¿liwym rozwi¹zaniem jest badanie charakterystyk tekstury w obrazie. W algorytmie tym piksele obrazu nie s¹ rozpatrywane w sposób jednostkowy, lecz znaczenie ma ich lokalne rozmieszczenie. Piksele tworz¹ wówczas grupy, które spe³niaj¹ pewne warunki jednorodnoœci. Grupy te wizualnie stanowi¹ lokalne wzorce przestrzenne, które formalnie mo¿emy okreœliæ jako tekstura. 

Jednym z narzêdzi s³u¿¹cych do wykrywania tekstur w obrazach jest filtr Gabora. Jest to filtr liniowy, którego reprezentacja czêstotliwoœciowa i orientacja jest zbli¿ona do ludzkiego systemu wizyjnego, przez co bardzo dobrze sprawdza siê jako deskryptor cech teksturalnych. Przetwarzaj¹c obraz z wykorzystaniem filtru Gabora o precyzyjnie dobranych parametrach jesteœmy zatem w stanie wydobyæ z obrazu wejœciowego informacjê o poszczególnych elementach sk³adowych obrazu, które spe³niaj¹ za³o¿one kryteria jednorodnoœci.

\cel{Celem pracy jest analiza wybranych metod cyfrowego przetwarzania obrazów, oraz ich praktyczna realizacja, która umo¿liwi automatyczn¹ klasyfikacjê obiektów na zobrazowaniach lotniczych i fotogrametrycznych.} 



\zakres{
Zakres pracy obejmuje:
\begin{itemize}
	\item opis struktury cyfrowych obrazów rastrowych, oraz wybranych metod ich przetwarznania
	\item matematyczny opis filtru Gabora; jego charakterystyki w dziedzinie czasowej i czêstotliwoœciowej 
	\item omówienie zagadnienia klasyfikacji obiektów, klasyczne i alernatywne metody jej realizacji
	\item zaproponowanie w³asnego algorytmu klasyfikacji obiektowej podstawie dostêpnej literatury
	\item praktyczn¹ realizacjê algorytmu w œrodowisku \textsc{MatLab} dla wybranych zobrazowañ lotniczych/fotogrametrycznych
	%\item porównanie uzyskanych wyników z klasycznymi metodami klasyfikacji obietków
\end{itemize}
} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% ROZDZIA£: WYbrane metody analizy obrazów cyfrowych %%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\mbox{przetwarzania}
\chapter{Charakterystyka rastrowych obrazów cyfrowych i wybrane metody ich przetwarzania}

W dobie nieustaj¹cego rozwoju technologicznego, w jakiej aktualnie siê znajdujemy, zdecydowana wiêkszoœæ zdalnie pozyskiwanych zdjêæ ma charakter cyfrowy. Cech¹ charakterystyczn¹ takiego zdjêcia jest jego rozdzielczoœæ -- skoñczona liczba pikseli (punktów) matrycy na których przechowywana jest informacja obrazowa.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%% Struktura rastrowych obrazów cyfrowych %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Struktura rastrowych obrazów cyfrowych}
Grafika rastrowa determinuje reprezentacjê obrazu jako dwuwymiarow¹ siatkê sk³adaj¹c¹ siê ze wczeœniej wspomnianych pikseli. Ka¿dy z pikseli natomiast przechowuje skoñczon¹ liczbê bêd¹c¹ informacj¹ o kolorze. Z samej ju¿ definicji wynika, ¿e reprezentacja ta jest nieci¹g³a (dyskretna). Obraz cyfrowy jest wiêc pewnym uproszczeniem w
stosunku do tego, co odbiera ludzki zmys³ wzroku. Samo ograniczenie rozmiaru obrazu cyfrowego wynika z potrzeby jego zapisu na skoñczonej liczbie bajtów w komputerze, jak równie¿ ograniczeñ wynikaj¹cych z mo¿liwoœci dalszego przetwarzania takiego obrazu. Ograniczenia te mog¹ byæ reprezentowane na wielu p³aszczyznach \cite{kompana}:
\begin{itemize}
\item ograniczenie zdolnoœci rozpoznawania szczegó³ów,
\item ograniczenie iloœci mo¿liwych do rozró¿nienia kolorów,
\item analizowanie obrazu p³askiego zamiast przestrzennego,
\item analizowanie obrazu statycznego zamiast dynamicznego.
\end{itemize}

Z formalnego punktu widzenia obraz mo¿emy zamodelowaæ przy u¿yciu funkcji (tzw. funkcji obrazu) dwóch zmiennych. Zmienne traktowane s¹ wówczas jako wspó³rzêdne i
okreœlaj¹ jasnoœæ obrazu w tym punkcie.

\begin{equation}
0 \leq L(x,y) < \infty
\end{equation}
gdzie:
\begin{flushleft}
$L$ -- funkcja obrazu (luminancji) \\
$(x,y)$ -- przestrzenna wspó³rzêdna funkcji L
\end{flushleft}

\begin{figure}[h]

    \centering
		    \begin{subfigure}{0.45\textwidth}
        \includegraphics[height= 5.5cm]{figures/zwykly}
        \caption{Obraz monochromatyczny}
				\label{mono}
         \end{subfigure}
   \:
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[height= 5.5cm]{figures/obraz3D}
       \caption{Obraz (a) jako funkcja $L(m,n)$}
        %\label{fig:tiger}
    \end{subfigure}

				\vspace{0.5cm}
		\caption[Obraz monochromatyczny i jego wykres gdy traktowany jest jako funkcja]{Obraz monochromatyczny i jego wykres gdy traktowany jest jako funkcja}
	\source{\url{http://earthexplorer.usgs.gov/}, opracowanie w³asne w œrodowisku \textsc{MatLab}}
	\label{obrazmono}
\end{figure}
Ka¿dy obraz rzeczywisty mo¿na przedstawiæ za pomoc¹ tej w³aœnie funkcji %(pamiêtajmy jednak, ¿e zawsze bêdzie on pewnym uproszczeniem). 
. Proces przejœcia z obrazu analogowego na cyfrowy nosi nazwê dyskretretyzacji. Sk³ada siê on z 2 zasadniczych procesów: próbkowania i kwantyzacji. W etapie próbkowania ci¹g³a dziedzina obrazu
analogowego zostaje zamieniona na skoñczony ci¹g próbek (w tym przypadku pikseli). W procesie kwantyzacji nastêpuje natomiast zmiana analogowej wartoœci janoœci na jej
dyskretny odpowiednik. W efekcie funkcja L(x,y) staje siê macierz¹ L(m,n) o M wierszach i N kolumnach. Rozmiary tej macierzy definiuj¹ rozdzielczoœæ przestrzenn¹ obrazu cyfrowego, a ka¿dy element tej macierzy przechowuje skwantowany poziom jasnoœci \cite{zygar}.
\begin{equation}
L(m,n) = \left[ \begin{array}{cccc} L(0,0) & L(0,1) & \dots & L(0,N-1) \\ L(1,1) & L(1,1) & \dots & L(1,N-1) \\ \vdots & \vdots &  \ddots & \vdots \\L(M-1,0) & L(M-1,1) & \dots & L(M-1,N-1) \end{array} \right]
\end{equation}

Wybór rozdzielczoœci obrazu decyduje o jego jakoœci, a co za tym idzie, ma kluczowe znaczenie przy rozpoznawaniu szczegó³ów obrazu. Oczywiœcie naturalne wydaje siê stwierdzenie, ¿e im wiêksza rozdzielczoœæ tym lepiej.  Okazuje siê jednak, ¿e spostrze¿enie te nie jest prawdziwe. Liniowy wzrost rozdzielczoœci poci¹ga za sob¹ kwadratowy wzrost czasu przetwarzania i objêtoœci samej reprezentacji \cite{kompana}. Odpowiednia rozdzielczoœæ powinna wiêc stanowiæ kompromis pomiêdzy zajmowan¹ objêtoœci¹ a mo¿liw¹ do uzyskania z obrazu informacj¹. 

Z punktu widzenia jakoœci obrazów cyfrowych bardzo wa¿nym parametrem jest równie¿ iloœæ dyskretnych stanów, któr¹ mo¿e przyjmowaæ pojedynczy piksel. Mo¿e byæ ona uto¿samiania z iloœci¹ kolorów reprezentowanych przez obraz. W zale¿noœci od tej liczby ró¿na bêdzie wielkoœæ pamiêci potrzebnej do zapisu obrazu (im wiêcej bêdzie dostêpnych dyskretnych stanów, tym wiêksza jest liczba bitów potrzebna do ich zapamiêtania). Podobnie jak w przypadku wyboru rozdzielczoœci, równie¿ wybór iloœci kolorów w obrazie powinien byæ kompromisem miêdzy zajmowan¹ pamiêci¹, a iloœci¹ zawartej w obrazie informacji. Najczêœciej wykorzystujemy jeden z podanych poni¿ej formatów obrazów:
\begin{itemize}
\item \textbf{binarny}
\item \textbf{monochromatyczny}
\item \textbf{kolorowy}
\end{itemize}
Ka¿dy z podanych powy¿ej formatów obrazów ma swoje specyficzne zastosowania.

\subsection{Obrazy binarne}
Jest to najprostszy z formatów obrazów rastrowych, zajmuj¹cy najmniej pamiêci (wymagany 1 bit na piksel). Wartoœæ koloru mo¿emy zakodowaæ za pomoc¹ 2 stanów -- 0 lub 1 (st¹d nazwa -- obraz binarny). Zazwyczaj przyjmuje siê, ¿e wartoœæ 0 reprezentuje kolor czarny, a wartoœæ 1 -- bia³y. Obrazy binarne s¹ czêsto pozyskiwane z obrazów monochromatycznych czy kolorowych do celów ich dalszego przetwarzania. Przetwarzanie obrazów odbywa siê wówczas znacznie szybciej, z u¿yciem ni¿szego kosztu obliczeniowego.

\begin{figure}[b!]

  \centering\includegraphics[scale= 0.55]{figures/bin}
	\vspace{0.5cm}
  \caption[Obraz binarny]{Obraz binarny}
	\source{\url{http://earthexplorer.usgs.gov/}, opracowanie w³asne w œrodowisku \textsc{MatLab}}
  %\label{fig:rysunek2}\source{Opracowanie na podstawie dokumentacji elektronicznej MATLAB 7.0 \cite{Matlab}}
\end{figure}

\subsection{Obrazy monochromatyczne}
Obrazy monochromatyczne (jednobarwne) charakteryzuj¹ siê tym, ¿e wartoœæ pojedynczego piksela wyra¿a jego wzglêdn¹ jasnoœæ. St¹d ich inna nazwa -- obrazy w skali szaroœci. Najczêœciej mamy do czynienienia z kodowaniem na 8 bitach (otrzymujemy wtedy $2^8 = 256$ dostêpnych poziomów szaroœci). Paleta kolorów zmienia siê wówczas od czarnego (reprezentuj¹cego wartoœæ 0) do bia³ego (wartoœæ 255). Przyk³ad takiego obrazu znajdziemy na Rys. (\ref{mono}).
%\begin{figure}[h]
	%\centering
		%\includegraphics[scale=0.8]{figures/piksel.png}
	%\caption{Reprezentacja obrazu cyfrowego}
	%\label{fig:piksel}
	%\source{Opracowanie w³asne}
%\end{figure}

\subsection{Obrazy kolorowe w przestrzeni barw RGB}
\label{kolorowe}
\begin{figure}[b!]

    \centering
		    \begin{subfigure}{0.41\textwidth}
        \includegraphics[width=\textwidth]{figures/rgbb}
        \caption{Obraz w przestrzeni barw RGB}
         \end{subfigure}
   \\
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{figures/r}
       \caption{Sk³adowa R}
        %\label{fig:tiger}
    \end{subfigure}
		\:
		\begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{figures/g}
       \caption{Sk³adowa G}
        %\label{fig:tiger}
    \end{subfigure}
		\:
		  \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{figures/b}
       \caption{Sk³adowa B}
        %\label{fig:tiger}
    \end{subfigure}
						
				\vspace{0.5cm}
		\caption[Obraz w przestrzeni barw RGB i jego sk³adowe]{Obraz w przestrzeni barw RGB i jego sk³adowe}
	\source{\url{http://earthexplorer.usgs.gov/}, opracowanie w³asne w œrodowisku \textsc{MatLab}}
	\label{filtrt}
\end{figure}
Obrazy kolorowe w przestrzeni barw RGB charakteryzuj¹ siê tym, ¿e ka¿dy piksel opisany jest za pomoc¹ 3 liczb. Liczby te nazywane s¹ sk³adowymi barwnymi, oznaczane s¹ literami R, G, B i okreœlaj¹ zawartoœæ barw podstawowych (odpowiednio: czerwonej, zielonej i niebieskiej) w pikselu. Kolor otrzymuje siê w wyniku zmieszania siê 3 sk³adowych. Zazwyczaj stosuje siê 24-bitowy zapis kolorów, w którym ka¿da sk³adowa przechowywana jest na 8 bitach. Nale¿y zwróciæ uwagê, ¿e w takim przypadku iloœæ mo¿liwych do uzyskania kolorów wyniesie $256^3 = 16 \; 777 \;216 $. Pojedynczy kolor RGB mo¿na wyznaczyæ ze wzoru:
\begin{equation}
 numer \: koloru= R \cdot 65536 + G \cdot 256 + B
\end{equation}
gdzie sk³adowe $R$, $G$, $B$ przyjmuj¹ wartoœci od $0$ do $255$. Gdy wszystkie sk³adowe osi¹gaj¹ wartoœæ $0$ mamy do czynienia z kolorem czarnym, natomiast dla wartoœci sk³adowych równych $255$ otrzymujemy kolor bia³y -- dla modelu RGB zachodzi synteza addytywna.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%% FILTRACJA SPLOTOWA %%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newpage
\section{Podzia³ metod przetwarzania obrazów}
Celem cyfrowego przetwarzania obrazów jest dokonanie takich przekszta³ceñ na obrazie wejœciowym, aby uzyskaæ z niego po¿¹dan¹ przez nas informacjê. Informacje te mog¹ byæ normalnie nie rozró¿nialne przez system wzrokowy cz³owieka.
\begin{figure}[b!]

  \centering\includegraphics[height = 6cm]{figures/podzial}
	\vspace{0.5cm}
  \caption[Podzia³ metod przetwarzania obrazów]{Podzia³ metod przetwarzania obrazów}
	\source{Opracowanie w³asne na podstawie \cite{zygar}}
\end{figure}

Generalnie mo¿na przyj¹æ, ¿e istnieje nieskoñczenie wiele metod przetwarzania obrazu. Jednak¿e metody przynosz¹ce praktyczne efekty stanowi¹ bardzo w¹sk¹ czêœæ ogó³u. Wœród nich mo¿emy wyró¿niæ pewne grupy przekszta³ceñ, które posiadaj¹ podobne cechy \cite{kompana}:
\begin{itemize}
\item przekszta³cenia geometryczne
\item przekszta³cenia punktowe (bezkontekstowe)
\item przekszta³cenia kontekstowe
\item przekszta³cenia widmowe (transformata Fouriera)
\item przekszta³cenia morfologiczne
\end{itemize}
Zasadniczy podzia³ na najczêœciej wykonywane operacja w poszczególnych grupach przekszta³ceñ zilustrowano na rysunku poni¿ej. 
\\ \\ Ze wzglêdu na przyjêt¹ w dalszej czêœci pracy metodykê prowadzonych badañ, w nastêpnej sekcji szczegó³owo opisano filtracjê splotow¹.
% PODZIA£ METOD PRZETWARZANIA OBRAZÓW
\section{Filtracja splotowa} \label{conv}

Filtracja splotowa (lub konwolucja, ang. \textit{convolution}) nale¿y do grupy przekszta³ceñ kontekstowych. Oznacza to, ¿e do wyznaczenia wartoœci pojedynczego piksela obrazu wyjœciowego potrzebne jest wykonanie obliczeñ na wielu pikselach obrazu wejœciowego.

Dla sygna³ów ci¹g³ych $f(t)$ i $g(t)$, bezwzglêdnie ca³kowalnych w przedziale $(-\infty,\infty)$ operacjê splotu mo¿emy zapisaæ jako:
\begin{equation}
y(t) = f(t)*g(t) = \int\limits_{-\infty}^{+\infty}{f(t-\tau)g(\tau)d\tau}
\label{splot}
\end{equation}
gdzie:
\begin{flushleft}
$ * $ -- operacja splotu \\
$ f,g $ -- funkcje splatane
\end{flushleft}

Poniewa¿ jak ju¿ wczeœniej wspomniano reprezentacja rastrowych obrazów cyfrowych  jest dwuwymiarowa i dyskretna, dlatego operacja splotu wymaga odpowiedniej adaptacji. W dziedzinie dyskretnej dzia³anie (\ref{splot}) znacznie siê upraszcza (ca³kowanie zastêpujemy sumowaniem), wobec czego konwolucjê dla dyskretnych sygna³ów dwuwymiarowych mo¿emy zapisaæ nastêpuj¹co:
\begin{equation}
L(x,y) = A(x,y) * I(x,y) = \sum\limits_{m=0}^{M-1}\sum\limits_{n=0}^{N-1}{A(m,n)\cdot I(x-m,y-n)}
\end{equation}
gdzie:
% zmieniæ te wypunktowanie na linie
\begin{flushleft}
$A$ -- obraz wejœciowy \\
$I$ -- maska filtru \\
$M,N$ -- rozmiar maski 

\end{flushleft}
Maska filtru jest tablic¹ zawieraj¹ca wspó³czynniki filtru. Jej rozmiary s¹ najczêœciej nieparzyste -- wystêpuje wtedy element centralny.  Sam¹ operacjê filtracji splotowej mo¿emy opisaæ w sposób nastêpuj¹cy:
\begin{itemize}
\item nak³adamy maskê filtru na obraz, tak aby jej element centralny pokrywa³ siê z aktualnie filtrowanym pikselem
\item wymna¿amy wspó³czynniki filtru z odpowiadaj¹cymi im pikselami obrazu wejœciowego
\item sumujemy wartoœæ otrzymanych iloczynów, a wynik przypisujemy do odpowiedniego piksela obrazu wyjœciowego 
\item operacjê powtarzamy iteracyjnie, pokrywaj¹c w ten sposób wszystkie piksele obrazu wejœciowego
\end{itemize}
Problem pojawia siê w przypadku filtracji pikseli brzegowych. Po ''na³o¿eniu'' maski na elementy skrajne obrazu czêœæ wspó³czynników filtru nie bêdzie mia³a swoich fizycznych odpowiedników na powierzchni obrazu (znajd¹ siê one poza jego zakresem). Stosuje siê wówczas jedn¹ z mo¿liwoœci:
\begin{figure}[b!]

  \centering\includegraphics[scale= 0.6]{figures/splocik}
	\vspace{0.5cm}
  \caption[Zasada dzia³ania splotu dyskretnego]{Zasada dzia³ania splotu dyskretnego}
	\source{Opracowanie w³asne}
  %\label{fig:rysunek2}\source{Opracowanie na podstawie dokumentacji elektronicznej MATLAB 7.0 \cite{Matlab}}
\end{figure}

\begin{itemize}
	\item pominiêcie brzegowcyh pikseli w obliczeniach (w efekcie zmniejszy siê rozmiar obrazu wyjœciowego),
	% CO TUTAJ JEST KURWA NAPISANE
	\item wirtualne powiêkszenie obrazu, tak aby maska pokrywa³a ca³y oryginalny obraz wejœciowy. Nowe elementy mo¿na uzupe³niæ na kilka sposobów: wype³niæ wartoœciami 0, powtórzyæ wartoœci z brzegów, wype³niæ wartoœciami z przeciwleg³ego brzegu oryginalnego obrazu.
\end{itemize}
Po operacji filtracji, obraz wynikowy musi spe³niaæ warunek normalizacji $L(x,y) \in [0,2^B -1]$ (B -- liczba bitów potrzebna do zapisu wartoœci jasnoœci pojedynczego piksela). Dlatego proces filtracji ka¿dorazowo powinien koñczyæ siê operacj¹ normalizacji -- skalowania danych do okreœlonego zakresu. Znormalizowane wartoœci $L'(x,y)$ obrazu wyjœciowego wyra¿aj¹ siê wzorem:
\begin{equation}
L'(x,y) = \frac{L(x,y)- min_{\forall m,n}L(m,n)}{max_{\forall m,n}L(m,n)-min_{\forall m,n}L(m,n)}\cdot 2^B
\end{equation}
Istnieje wiele rodzajów filtrów splotowych, jednak¿e wyró¿niæ mo¿emy tutaj przede wszystkim filtry: 
\begin{itemize}
	\item \textbf{dolnoprzepustowe} --  t³umi¹ elementy o wysokiej czêstotliwoœci, przepuszczaj¹ elementy o niskiej; s³u¿¹ do wyg³adzania obrazu, usuwania zak³óceñ,
	\item \textbf{górnoprzepustowe} -- dzia³aj¹ odwrotnie do filtrów dolnoprzepustowych: przepuszczaj¹ wysokie czêstotliwoœci, a t³umi¹ niskie; s³u¿¹ do ekstrakcji szczegó³ów, zazwyczaj przez zwiêkszenie kontrastu,
	\item \textbf{pasmowoprzepustowe} -- przepuszczaj¹ sk³adowe widma obrazu o okreœlonej czêstotliwoœci; uwypuklaj¹ okreœlone cechy obrazu, podkreœlaj¹ krawêdzie, akcentuj¹ teksturê. 
\end{itemize}

%\begin{figure}[h!]
%
    %\centering
		    %\begin{subfigure}{0.46\textwidth}
        %\includegraphics[scale=0.45]{figures/dolno}
        %\caption{Dolnoprzepustowy}
			  %\end{subfigure}
   %%\:
    %\begin{subfigure}{0.46\textwidth}
        %\includegraphics[scale=0.45]{figures/gorny}
       %\caption{Górnoprzepustowy}
        %%\label{fig:tiger}
    %\end{subfigure}
%
				%\vspace{0.5cm}
		%\caption[Filtr dolno i gornoprzepustowy]{Filtr dolno- i gornoprzepustowy}
	%\source{\url{http://earthexplorer.usgs.gov/}, adaptacja w³asna}
	%\label{aey}
%\end{figure}
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% FILTR GABORA %%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Filtr Gabora}

Filtr Gabora jest filtrem pasmowoprzepustowym. Jego twórc¹ jest Dennis Gabor, wêgierski laureat Nagrody Nobla w dziedzinie fizyki (1900-1979). Filtr ten wykorzystywany jest g³ównie do detekcji tekstur w obrazach, oraz przy wykrywaniu krawêdzi. W cyfrowym przetwarzaniu obrazów mo¿na go realizowaæ w dziedzinie przestrzennej poprzez dyskretn¹ dwuwymiarow¹ konwolucjê z wyliczon¹ mask¹ lub przez zwyk³e mno¿enie w dziedzinie czêstotliwoœci (wykorzystujemy tutaj twierdzenie o splocie).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% DZIEDZINA CZASU %%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Dziedzina czasu}
W dziedzinie przestrzennej filtr charakteryzowany jest jako zespolona sinusoida (ang. carrier) modulowana funkcj¹ Gaussa (funkcjê tê okreœla siê jako koperta, ang. envelope).
%% RÓWNANIE FUNKCJI GABORA W DZIEDZINIE CZASU
\begin{equation}
g(x,y,f,\theta) = e^{-\frac{1}{2}\left(\frac{x_\theta^2}{\sigma_x^2}+\frac{y_\theta^2}{\sigma_y^2} \right)} \times e^{j 2 \pi f x_\theta}
\label{maineq}
\end{equation}
gdzie $f$ jest czêstotliwoœci¹ fali sinusoidalnej, $\theta$ -- orientacj¹ filtru Gabora, $\sigma_x$ , $\sigma_y$ s¹ ostroœciami filtru odpowiednio wzd³u¿ osi $x$ i $y$. Wspó³rzêdne $x_\theta$ oraz $y_\theta$ s¹ w obrócone w p³aszczyŸnie $xy$ o k¹t $\theta$. Ich wspó³rzêdne mo¿emy wyliczyæ zgodnie ze wzorem:

\begin{eqnarray}
\begin{array}{cccccc}
 x_{\theta} & = &  &x \cos\theta& + &y\sin\theta \\
 y_{\theta} & = & - &x\sin\theta & + &y\cos\theta 

\end{array}
\label{eqrot2}
\end{eqnarray}
Zgodnie z twierdzeniem Eulera wzór (\ref{maineq}) mo¿emy przedstawiæ jako:
\begin{equation}
g(x,y,f,\theta) = e^{-\frac{1}{2}\left(\frac{x_\theta^2}{\sigma_x^2}+\frac{y_\theta^2}{\sigma_y^2} \right)} \times \left( \cos(2\pi f x_\theta) + j  \sin(2 \pi f x_\theta) \right)
\end{equation}
Na podstawie tego wzoru jawnie widaæ ¿e filtr ma 2 czêœci: rzeczywist¹ i urojon¹. W
zastosowaniach praktycznych czêsto zamiast zespolonej postaci funkcji Gabora wyko-
rzystuje siê jego postaæ rzeczywist¹. Wybiera siê wówczas modulacjê tylko fal¹ sinuso-
idaln¹ lub cosinusoidaln¹. Ze wzglêdu na w³aœciwoœci tych funkcji trygonometrycznych
w swojej dziedzinie mówimy wówczas ¿e filtr jest nieparzysty (w przypadku modula-
cji sinusem) lub parzysty (modulacja cosinusem). W znacz¹cej czêœci przypadków do
filtracji u¿ywamy filtru parzystego (ang. Even).
\begin{figure}[h!]

    \centering
		    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/filtrsin}
        \caption{Zespolona sinusoida -- czêœæ parzysta}
         \end{subfigure}
   \:
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/filtrenv}
       \caption{Koperta Gaussa}
        %\label{fig:tiger}
    \end{subfigure}
		\\
		\begin{subfigure}{0.6\textwidth}
        \includegraphics[width=\textwidth]{figures/filtrall}
       \caption{Filtr Gabora -- czêœæ parzysta}
        %\label{fig:tiger}
    \end{subfigure}
				
				\vspace{0.5cm}
		\caption[Filtr Gabora w dziedzinie czasu (przestrzennej)]{Filtr Gabora w dziedzinie czasu (przestrzennej). Parametry: $f = 0.3$, $\theta = \pi/3$, $\sigma_x=\sigma_y= 2$}
	\source{Opracowanie w³asne w œrodowisku \textsc{MatLab}}
	\label{filtrt}
\end{figure}


% to póŸniej skasowaæ
%\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% DZIEDZINA CZÊSTOTLIWOŒÆI %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Dziedzina czêstotliwoœci}

%% RÓWNANIE FUNKCJI GABORA W DZIEDZINIE CZÊSTOTLIWOŒCI
%% TUTAJ COŒ SIÊ NIE ZGADZA ?!!!!! sk¹d by³ brany wzór ??
Dokonuj¹c transformaty Fouriera funkcji danej wzorem (\ref{maineq}) otrzymujemy równanie filtru Gabora w dziedzinie czêstotliwoœciowej:
\begin{equation}
G(u,v,f,\theta) = \frac{1}{2\pi\sigma_u\sigma_v}\left[e^{-\frac{1}{2}\left(\frac{(u_\theta-u_0)^2}{\sigma_u^2}+\frac{(v_\theta-v_0)^2}{\sigma_v^2} \right)} + e^{-\frac{1}{2}\left(\frac{(u_\theta+u_0)^2}{\sigma_u^2} + \frac{(v_\theta+v_0)^2}{\sigma_v^2} \right)} \right]
\label{maineqf}
\end{equation}
gdzie $u_0$, $v_0$ s¹ równe odpowiednio $\frac{2\pi\cos\theta}{f}$, $\frac{2\pi\sin\theta}{f}$. Ponadto zachodzi zale¿noœæ:
\begin{eqnarray}
\begin{array}{cccccc}
 u_{\theta} & = &  &u \cos\theta& + &v\sin\theta \\
 v_{\theta} & = & - &u\sin\theta & + &v\cos\theta 
\label{eqrot}
\end{array}
\end{eqnarray}
\newpage
\begin{figure}[t!]
  \centering\includegraphics[scale= 0.6]{figures/filtrdzf}
	\vspace{0.5cm}
  \caption[Filtr Gabora w dziedzinie czêstotliwoœci]{Filtr Gabora w dziedzinie czêstotliwoœci. Parametry identyczne jak dla filtru z Rysunku \ref{filtrt}}
	\source{Opracowanie w³asne w œrodowisku \textsc{MatLab}}
  %\label{fig:rysunek2}\source{Opracowanie na podstawie dokumentacji elektronicznej MATLAB 7.0 \cite{Matlab}}
\end{figure}

Nale¿y zwróciæ uwagê ¿e filtracjê obrazu z wykorzystaniem filtru Gabora mo¿emy realizowaæ zarówno w dziedzinie przestrzennej, jak i czêstotliwoœciowej. W przypadku dziedziny przestrzennej postêpujemy zgodnie z algorytmem przedstawionym w sekcji \ref{conv}. Decyduj¹c siê na dziedzinê czêstotliwoœci wymagane jest wyliczenie dwuwymiarowej transformaty Fouriera na obrazie wejœciowym, a po przeprowadzeniu operacji obliczenie odwrotnej transformaty Fouriera. Natomiast sama konwolucja obrazu z mask¹ odbywa siê wówczas jako zwyk³e mno¿enie.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% ROZDZIA£ PROCEDURY KLASYFIKACYJNE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Fotointerpretacja i techniki klasyfikacyjne}
% wydaje mi siê ¿e tutaj nale¿y wspomnieæ o wysokorozdzielczych dnaych teledetykcyjnych, pojêcie fa³szycwych kolorów , zdjêcia wielospektralne, hiperspektralne,
% WE WSTÊPIE OGÓLNIE O TELEDEKCJI
Wykorzystuj¹c odpowiednie urz¹dzenia jesteœmy w stanie rejestrowaæ wszystkie zakresy promieniowania elektromagnetycznego, oraz badaæ na tej podstawie zarówno obiekty jak i zjawiska emituj¹ce lub odbijaj¹ce energiê elektromagnetyczn¹, jak równie¿ analizowaæ ich reakcjê na okreœlone zakresy spektrum\cite{inter}.
 
Metody rejestracji tego promieniowania, nie wymagaj¹ bezpoœredniego kontaktu z badanym obiektem.  Taki rodzaj badañ mo¿emy wiêc nazwaæ metodami zdalnymi lub bezkontaktowymi. Od lat szeœædziesi¹tych zesz³ego stulecia przyjêto nazywaæ je teledetekcj¹. Same efekty tej rejestracji -- zobrazowania teledetekcyjne sta³y siê przedmiotem interpretacji, bêd¹c zasadniczym Ÿród³em informacji w procesie zdalnego badania œrodowiska. 

Mówi¹c o teledetekcji mo¿emy dostrzec jej zasadniczy zwi¹zek  z inn¹ dziedzin¹ naukow¹ -- fotogrametri¹. Niew¹tpliwie, dziedziny te wzajemnie siê pokrywaj¹. Ich wspólnym mianownikiem jest oparcie siê na tej samej informacji -- informacji obrazowej. Pod koniec ubieg³ego stulecia, w 1998 roku w Kioto (Japonia), na XVI Kongresie MTFiT (Miêdzynarodowego Towarzystwa Fotogrametrii i Teledetekcji, ang. ISPRS -- \textit{International Society for Photogrammetry and Remote Sensing}) dostrze¿ono koniecznoœæ rozpatrywania fotogrametrii i teledetekcji w sposób ³¹czny, oraz podano ich wspóln¹ definicjê, która brzmi: ''dziedzina nauk technicznych zajmuj¹ca siê zdalnym pozyskiwaniem wiarygodnych informacji o obiektach fizycznych i ich otoczenia drog¹ rejestracji, pomiaru i interpretacji i zdjêæ''\cite{butowt}. 
\section{Fotointepretacja}
%%%%%%%%%%%%%%%%%% FOTOINTERPRETACJA  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FOTOINTERPRETACJA – metoda badania (obserwacji i analizy) zdjêæ fotograficznych w
%celu identyfikacji obiektów, rozpoznawania procesów i zjawisk, oraz wnioskowania o %ich funkcji czy znaczeniu

Jak ju¿ wspomniano na wstêpie proces zdalnego badania œrodowiska opiera siê na interpretacji zdjêæ. Najstarszym jej dzia³em jest oparta na zdjêciach i zobrazowaniach fotointerpretacja, wci¹¿ maj¹ca szerokie zastosowanie w pracach topograficznych i~fotogrametrycznych\cite{Tele}. Pod tym pojêciem nale¿y rozumieæ metodê detekcji i identyfikacji obiektów na zdjêciach fotograficznych, na podstawie analizy ich cech rozpoznawczych. 

Niew¹tpliwie na przestrzeni czasu samo podejœcie do fotointepretacji bardzo siê zmieni³o. Samo pojêcie zosta³o sformu³owane znacznie wczeœniej od momentu wystrzelenia pierwszych satelit serii Landsat na orbitê (czyli pocz¹tku ery cyfrowych danych teledetekcyjnych). Dynamiczny jej rozwój przypad³ zw³aszcza na okres miêdzywojenny (wtedy te¿ czêœæ by³ych wojskowych którzy zapoznali siê z fotointepretacj¹ w czasie wojny zaczê³a stosowaæ zdjêcia lotnicze w cywilnej pracy zawodowej)\cite{inter}. W tamtych czasach mogliœmy mówiæ o interpretacji wizualnej (analogowej). Ci¹gle nieustaj¹cy rozwój technologii cyfrowej dostarczy³ nam nowych rozwi¹zañ w tej dziedzinie. Obecnie fotointerpretacja ewoluujê w stronê zautomatyzowanej analizy obrazów cyfrowych wykorzystuj¹cej systemy komputerowe. Wykorzystuj¹c odpowiednie algorytmu komputerowe, wzorowane na empiryzmie w analogowej intepretacji obrazów, systemy te maj¹ za zadanie przeprowadzaæ numeryczn¹ klasyfikacjê treœci obrazów cyfrowych (patrz sekcja \ref{klasyfik}).


% coœ tam wielospektralne
\subsection{Kompozycje barwne}
Decyduj¹c siê na interpretacjê wizualn¹ zobrazowañ teledetekcyjnych nale¿y zwróciæ uwagê, ¿e proces ten jest d³ugotrwa³y i wymaga zastosowania specjalistycznych podk³adów mapowych. Aby usprawniæ proces interpretacji, a tak¿e poszerzyæ zakres informacji któr¹ mo¿na uzyskaæ z pojedynczej sceny, stosuje siê zapis obrazu w kana³ach spektralnych. Zestawienie 3 takich obrazów, zapisanych w odpowiednich pasmach promieniowania elektromagnetycznego nazywamy kompozycj¹ barwn¹ obrazów satelitarnych \cite{piech}. Zwróæmy uwagê, ¿e obraz wielospektralny mo¿e sk³adaæ siê z wielu kana³ów spektralnych, jednak¿e decyduj¹c siê na wyœwietlenie go jako obrazu w przestrzeni barw RGB (patrz sekcja \ref{kolorowe}) bêdzie on zawsze kombinacj¹ 3 dowolnych kana³ów obrazu wielospektralnego. % (czyli obrazu pokrywaj¹
\begin{table}[b!]
\centering

\caption{Kana³y wykorzystane do generowania kompozycji barwnych}
\vspace{5pt}
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{1}{|c|}{\textbf{Zdjêcie}} & \textbf{Przestrzeñ barw} & \textbf{Kolejnoœæ kana³ów} \\ 
\hline
\ref{barwne0} & RGB & 1,2,3 \\ 
\hline
\ref{barwne1} & RGB & 3,1,2 \\ 
\hline
\ref{barwne2} & RGB & 2,3,1 \\ 
\hline
\end{tabular}
\label{kanatab}
\end{table}

Kompozycjê w barwach naturalnych uzyskamy tylko i wy³¹cznie gdy do sk³adowych RGB obrazu cyfrowego podstawimy odpowiednio: dla sk³adowej R -- kana³ czerwony obrazu wielospektralnego, G -- kana³ zielony, oraz B -- kana³ niebieski. W ka¿dym innym przypadku uzyskamy kompozycjê w barwach fa³szywych. Przyk³ad kompozycji barwnych dla zobrazowania satelitarnego przedstawiono na rysunku \ref{superbarwne}. Do tworzenia kompozycji wykorzystano zawarte w tabeli \ref{kanatab} kana³y (przyjmujemy ich numeracjê: 1 -- kana³ czerwony, 2 -- zielony, 3 -- niebieski).

Kompozycje barwne znacznie u³atwiaj¹ rozpoznawalnoœæ obiektów terenowych dziêki wykorzystaniu barw i ich tonów, a nie odcieni szaroœci. Dodatkowo, w zale¿noœci od zakresów spektralnych, z jakich sk³ada siê kompozycja, uwypuklone s¹ inne elementy œrodowiskowe sceny \cite{piech}.

% KANA£Y
% OBRAZ 1 R: Band 3 G: Band 1 B: Band 2
% OBRAZ 2 R: Band 2 B G: Band 3 B: Band 1
% OBRAZ 3 R: G: B: 

\begin{figure}[t!]

    \centering
		    \begin{subfigure}{0.6\textwidth}
        \includegraphics[width=\textwidth]{figures/barwne0}
        \caption{Obraz w barwach naturalnych}
				\label{barwne0}
         \end{subfigure}
   \\
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/barwne1}
       \caption{Obraz (a) w barwach fa³szywych}
			\label{barwne1}
        %\label{fig:tiger}
    \end{subfigure}
   \:
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/barwne2}
       \caption{Obraz (a) barwach fa³szywych}
			\label{barwne2}
        %\label{fig:tiger}
    \end{subfigure}
				
				\vspace{0.5cm}
		\caption[Obraz satelitarny i jego kompozycje barwne]{Obraz satelitarny i jego kompozycje barwne}
	\source{\url{http://earthexplorer.usgs.gov/}, opracowanie w³asne w œrodowisku ArcGIS}
		\label{superbarwne}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%% SEKCJA KLASYFIKACJA I METODY ... %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Klasyfikacja i metody jej prowadzenia} \label{klasyfik}
Jak ju¿ wczeœniej wspomniano klasyfikacja (lub bardziej formalnie: klasyfikacja treœci obrazów cyfrowych) jest pewn¹ ewolucj¹ procesu fotointerpretacji, gdy¿ nie jest ona wykonywana w sposób analogowy przez fotointerpretatora, lecz do intepretacji wykorzystywany jest system komputerowy, który dokonuje pewnych operacji na obrazie wejœciowym.

Sam proces klasyfikacji polega na przypisaniu poszczególnych pikseli obrazu do okreœlonej klasy. Klasami tymi s¹ zazwyczaj obszary o okreœlonej kategorii u¿ytkowania (np. tereny zielone, ³¹ki, lasy, obszary zurbanizowane itd.). Celem klasyfikacji jest zatem synteza pikseli o podobnych w³aœciwoœciach. Zauwa¿my, ¿e ka¿dy piksel oprócz informacji o swoim usytuowaniu w macierzy obrazu przechowuje równie¿ informacjê o jasnoœci w danym kanale spektralnym. Z tego wzglêdu klasyfikacja mo¿e dotyczyæ \cite{Tele}
\begin{itemize}
	\item jasnoœci pikseli w poszczególnych kana³ach spektralnych, 
	\item tekstury (struktury) obrazu na podstawie ró¿nych miar przestrzennych zmian jasnoœci pikseli i ich po³o¿enia,
	\item kryteriów rozszerzonych, do których poza wymienionymi powy¿ej w³¹cza siê dodatkowe spoza kana³ów spektralnych zobrazowania.
\end{itemize}
Takie podejœcie wymaga zastosowania ró¿nych technik klasyfikacyjnych, które bêd¹ adekwatne do naszych potrzeb. W procesie klasyfikacji mo¿emy zatem wyró¿niæ kilka wiod¹cych metod :
\begin{itemize}
	\item nadzorowan¹ 
	\item nienadzorowan¹ 
	\item obiektow¹
\end{itemize}

Zasadnicza ró¿nica miêdzy tymi metodami to inaczej zdefiniowane wzorce klas, na podstawie których podczas samego procesu nastêpuje rozpoznanie poszczególnych form pokrycia terenu \cite{Lew}. Pierwsze 2 metody bazuj¹ na statystycznym rozk³adzie wartoœci jasnoœci pikseli (piksele o podobnej wartoœci odpowiedzi spektralnej bêd¹ skupia³y siê w grupach), natomiast metoda 3 bierze pod uwagê rozk³ad przestrzenny pikseli (wa¿ne jest ich lokalne rozmieszczenie).
\subsection{Klasyfikacja nadzorowana}
Klasyfikacja nadzorowana wymaga uczestnictwa analityka, który posiada wiedzê aprioryczn¹ na temat badanego obszaru (znane s¹ wystêpuj¹ce typy pokrycia terenu). Zadaniem analityka jest wskazanie konkretnych miejsc (obszarów homogenicznych), które stanowiæ bêd¹ wzorce klas. Obszary te nazywane s¹ polami treningowymi. Na podstawie charakterystyk spektralnych dla ka¿dego z pól treningowych wyliczany jest szereg parametrów statystycznych (œrednia, odchylenie standardowe, macierz kowariancji, macierz korelacji, itp.). Nastêpnie wszystkie piksele obrazu wejœciowego zostaj¹ ocenione i przydzielone do klasy, której s¹ najbardziej prawdopodobnym cz³onkiem. 

Przyk³ad przeprowadzenia klasyfikacji nadzorowanej na danych teledetekcyjnych zilustrowano na rysunku \ref{super}. W fazie wstêpnej zdefiniowano 4 klasy reprezentuj¹ce nastêpuj¹ce formy pokrycia terenu (wykorzystano tutaj wiedzê aprioryczn¹):
\begin{enumerate}
	\item Obszary miejskie -- kolor ró¿owy
	\item Cieki wodne -- kolor niebieski
	\item Lasy -- kolor zielony
	\item Grunty  rolne -- kolor ¿ó³ty
\end{enumerate}
\begin{figure}[t!]

    \centering
		    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/mapa}
        \caption{Zobrazowanie z satelity Landsat}
         \end{subfigure}
   \:
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/supervised}
       \caption{Efekt klasyfikacji nadzorowanej}
        %\label{fig:tiger}
    \end{subfigure}
 
				
				\vspace{0.5cm}
		\caption[Klasyfikacja nadzorowana]{Klasyfikacja nadzorowana}
	\source{\url{http://earthexplorer.usgs.gov/}, opracowanie w³asne w œrodowisku ArcGIS}
	\label{super}
\end{figure}

% KLASYFIKACJA NIENADZOROWANA
%\newpage % SZTUCZNE WYMUSZENIE
\subsection{Klasyfikacja nienadzorowana}
W przeciwieñstwie do klasyfikacji nadzorowanej, klasyfikacja nienadzorowana cechuje siê pe³n¹ automatyzacj¹. Jedyne czego wymaga algorytm to podanie od analityka liczby klas do których maj¹ zostaæ zakwalifikowane dane wejœciowe. Wzorce klas tworzone s¹ w sposób automatyczny, a piksele obrazu wejœciowego s¹ do nich przypisywane w zale¿noœci od spe³nienia warunków przynale¿noœci do konkretnej klasy. Zsyntezowane piksele spe³niaj¹ce jednakowe warunki przynale¿noœci tworz¹ klastry, którym to przypisuje siê odpowiedni¹ formê pokrycia terenu.  Zwróæmy uwagê na zasadnicz¹ ró¿nicê miêdzy klasyfikacj¹ nadzorowan¹ i nienadzorowan¹: o ile w przypadku tej pierwszej to analityk wskazuje obszary homogeniczne (na podstawie wiedzy a priori), to w przypadku tej drugiej algorytm wyznacza je w sposób automatyczny. Klasyfikacja nienadzorowana mo¿e zatem dostarczaæ informacji dotycz¹cej liczby mo¿liwych do rozró¿nienia form terenu \cite{Tele}. 
\begin{figure}[b!]

    \centering
		    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/mapa}
        \caption{Zobrazowanie z satelity Landsat}
         \end{subfigure}
   \:
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{figures/unsuper}
       \caption{Efekt klasyfikacji nienadozrowanej}
		\end{subfigure}
		
				\vspace{0.5cm}
		\caption[Klasyfikacja nienadzorowana]{Klasyfikacja nienadzorowana}
	\source{\url{http://earthexplorer.usgs.gov/}, opracowanie w³asne w œrodowisku ArcGIS}
	\label{unsuper}
\end{figure}

Przyk³ad przeprowadzenia klasyfikacji nienadzorowanej ziulustrowano na rysunku \ref{unsuper}. Wykorzystano ten sam obraz wejœciowy jak na rysunku \ref{super}. W fazie wstêpnej przyjêto ¿e obraz wyjœciowy sk³adaæ ma siê z 10 klas (klasom nie przypisywano form pokrycia terenu).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% KLASYFIKACJA OBIEKTOWA %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Klasyfikacja obiektowa}
Klasyfikacja obiektowa znacz¹co ró¿ni siê od dwóch wczeœniej wspomnianych metod. Jest ona stosunkow¹ now¹ technik¹ klasyfikacji zdjêæ satelitarnych i w nied³ugim okresie mo¿e zast¹piæ tradycyjne metody klasyfikacji \cite{Lew3}. W algorytmie tym piksele nie s¹ analizowane pojedynczo (nie sprawdzamy przynale¿noœci ka¿dego piksela do poszczególnych klas) lecz badane s¹ grupy pikseli spe³niaj¹ce pewne kryteria jednorodnoœci. Klasyfikacja wykonywana jest nie tylko na podstawie statystycznych rozk³adów wartoœci odbiæ spektralnych charakteryzuj¹cych obiekty, lecz z zastosowaniem informacji o ich geometrii i teksturze \cite{Lew2}.

To w³aœnie tekstura jest pojêciem kluczowym w procesie klasyfikacji obiektowej. Mo¿emy j¹ definiowaæ jako pewien obszar w obrazie, spe³niaj¹cy kryteria jednorodnoœci. Jednorodnoœæ ta zwi¹zana jest z percepcj¹ uk³adu wzorkowego cz³owieka. Do kryteriów jednorodnoœci mo¿emy zaliczyæ cechy powierzchni obiektu takie jak: kierunkowoœæ, jasnoœæ, chropowatoœæ. Mo¿liwie jest zatem przeprowadzenie klasyfikacji w oparciu o charakteryzuj¹ce obiekty teksturê.

Przeprowadzenie klasyfikacji obiektowej dla wybranych przez autora pracy obrazów cyfrowych stanowi problem badawczy w niniejszej pracy i zosta³o ono szczegó³owo opisane i zwizualizowane w Rozdziale \ref{algorytm}. W tym miejscu nale¿y równie¿ zwróciæ uwagê na zasadnoœæ wykorzystania filtrów Gabora do klasyfikacji obiektowej. Poniewa¿ jak ju¿ wczeœniej wspomniano, jednym z jego typowych zastosowañ jest deskrypcja cech teksturalnych, dlatego bêdzie odgrywa³ on kluczow¹ rolê w przeprowadzeniu wy¿ej wymienionego algorytmu.
%%%%%%%%%%%%%%%%%%%%%%% ROZDZIA£ PRAKTYCZNY - IMPLEMENTACJA %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementacja filtru Gabora w œrodowisku \textsc{MatLab} }

\section{Opis funkcjonalnoœci programu}

\chapter{Realizacja algorytmu automatycznej klasyfikacji obiektów}
\label{algorytm}
\section{Metodyka dzia³añ}
\subsection{Dobór parametrów filtru}
\subsection{Wybór metody klasyfikacji}
\section{Realizacja algorytmu dla 3 wybranych przypadków}

\Zakonczenie
Podsumowanie i wnioski
%W~tym miejscu nale¿y umieœciæ zakoñczenie pracy przygotowane zgodnie
%z~wczeœniejszymi zaleceniami (patrz rozdzia³~\ref{sec:zakonczenie}
%na stronie~\pageref{sec:zakonczenie}).
%
%
%%
%% Za³¹czniki (opcjonalnie):
%\appendix
%\chapter{Tytu³ za³¹cznika jeden\label{chap:app1}}
%
%Treœæ za³¹cznika jeden. Mog¹ to byæ elementy zwi¹zane z~opisem
%technicznym wykonanych w~pracy urz¹dzeñ, programów, dokumentacj¹
%projektow¹ itp. Mog¹ to byæ równie¿ Ÿród³a literaturowe w~postaci
%kart katalogowych najistotniejszych elementów elektronicznych u¿ytych
%w~projektowanym urz¹dzeniu itp.
%
\appendix
\chapter{Zawartoœæ dodatkowej p³yty CD-ROM\label{chap:appCD}}

W~tym rozdziale powinno siê przedstawiæ \textbf{zawartoœæ DODATKOWEJ p³yty CD do³¹czonej
ewentualnie do wydrukowanej pracy}, która zawiera kody programów,
wersje elektroniczne dokumentacji, materia³y dodatkowe zebrane przez
studenta itp.

\noindent \textbf{Uwaga! Nie jest to opis p³yty, zawieraj¹cej wersjê elektroniczn¹ pracy, ale p³yty dodatkowej, nieobowi¹zkowej.}

\begin{thebibliography}{15}

\bibitem{Tele}
Sanecki J., Stêpieñ G., Konieczny J., Niebylski J., Klewski A.:
\newblock {\em Teledetekcja. Wykorzystanie zdalnej informacji}.
\newblock Wydawnictwo Naukowe Akademii Morskiej, 2015.

\bibitem{butowt}
Butowtt J., Kaczyñski R.:
\newblock{\em Fotogrametria}
\newblock{Wydawnictwo Wojskowej Akademii Technicznej, Warszawa 2003.}

\bibitem{inter}
Cio³kosz A., Mieszalski J., Olêdzki J.:
\newblock {\em Interpretacja zjdêæ lotniczych.}
\newblock {PWN, Warszawa 1999.}



\bibitem{SIP}
Bielecka E., Maj K.:
\newblock {\em Systemy informacji przestrzennej. Podstawy teoretyczne.}
\newblock Wojskowa Akademia Techniczna, Warszawa 2009.

\bibitem{zygar}
Zygarlicka M.:
\newblock {\em Wybrane metody przetwarzania obrazów w analizach czasowo-czêstotliwoœciowych na przyk³adzie zak³óceñ w sieciach elektroenergetycznych}.
\newblock {Autoreferat rozprawy doktorskiej, wydawnictwo Politechniki Opolskiej, Opole 2011.}

\bibitem{raster}
Kubik T., Paluszyñski W., Iwaniak A. Tymków P.:
\newblock {\em Klasyfikacja obrazów rastrowych~z wykorzystaniem sztucznych sieci neuronowych i statystycznych metod klasyfikacji}.
\newblock Wydawnictwo Uniwersytetu Przyrodniczego we Wroc³awiu, Wroc³aw 2008.

\bibitem{Lew}
Lewiñski S.:
\newblock {\em Obiektowa klasyfikacja zdjêæ satelitarnych jako metoda pozyskiwania informacji o pokryciu i u¿ytkowaniu Ziemii.}
\newblock Instytut Geodezji i Kartografii PW, Warszawa 2007.

\bibitem{Lew2}
Lewiñski S.:
\newblock{\em Rozpoznanie form pokrycia i u¿ytkowania Ziemii na zdjêciu satelitarnym Landsat ETM+ metod¹ klasyfikacji obiektowej}.
\newblock{Polskie Towarzystwo Informacji Przestrzennej, Roczniki Geomatyki,
tom IV, z. 3, s. 139-150.}

\bibitem{Lew3}
Lewiñski S.:
\newblock {\em Porównanie klasyfikacji obiektowej z tradycyjn¹ klasyfikacj¹ pikselow¹ z punktu widzenia automatyzacji procesu tworzenia bazy danych o pokryciu i u¿ytkowaniu terenu.}
\newblock {Roczniki Geomatyki 2007, Tom V, Zeszyt 1}

\bibitem{piech}
Piech I., Dro¿dz B.:
\newblock {\em Obrazy satelitarne jako Ÿród³o informacji o krajobrazie.}
\newblock {Infrastruktura i ekologia terenów wiejskich, Nr 3/2010, s. 41-54}

\bibitem{marmol1}
Marmol U., Lenda G.:
\newblock {\em Filtry teksturalne w procesie automatycznej klasyfikacji obiektów}.
\newblock {Archiwum Fotogrametrii, Kartografii i Teledetekcji, Vol. 21, 2010, s. 235-243}

\bibitem{kompana}
Tadeusiewicz R., Korohoda P.:
\newblock {\em Komputerowa analiza i przetwarzanie obrazów}
\newblock{Wydawnictwo Fudacji Postêpu telekomunikacji, Kraków 1997}

\bibitem{marmol2}
Marmol U.:
\newblock{\em Use of Gabor filters for texture classification of airobrne images and lidar data}.
\newblock{Archives of Photogrammetry, Cartography and Remote Sensing, Vol. 22, 2011, pp. 325-336}



\bibitem{design}
Vo\ss{} N., Mertsching B.:
\newblock{\em Design and Implementation of an Accelerated
Gabor Filter Bank Using Parallel Hardware}.
% TUTAJ TRZEBA JESZCZE SPRAWDZIÆ CZY DOBRZE
\newblock{Technical Report (?),University of Hamburg, Department of Computer Science}.

\bibitem{effic}
Ilonen J., K\"am\"ar\"ainen J.-K., Kalvi\"ainen H.:
\newblock{\em Efficient Computation of Gabor Features}.
\newblock{Lappeenranta 2005}

\bibitem{opttex}
Clausi D. A., Jernigan M. E.: 
\newblock{\em Designing Gabor filters for optimal texture separability.}
\newblock{Pattern Recognition 33, s. 1835–1849., 2000}

\bibitem{accurate}
Amayeh G., Tavakkoli A., Bebis G.:
\newblock {\em Accurate and Efficient Computation of Gabor
Features in Real-Time Applications}
% dokoñczyæ tê pozycjê !!

\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%% SPIS RYSUNKÓW %%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listoffigures

%%%%%%%%%%%%%%%%%%%%%% SPIS TABEL %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listoftables


%%%%%%%%%%%%%%%%%%%%%% SPIS KODÓW RÓD£OWYCH %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listof{Program}{Spis kodów Ÿród³owych}
\addcontentsline{toc}{chapter}{Spis kodów Ÿród³owych}


%% Skorowidz (opcjonalnie)
\printindex


\end{document}
